{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73eb75c7-3c6a-40ec-b348-60185432e63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 0...\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Done ✅ Scraped 227 listings.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "Base_URL = 'https://privateproperty.ng'\n",
    "start_page = 0\n",
    "end_page = 16\n",
    "\n",
    " # Setting headers \n",
    "Headers = {\"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.6261.95 Safari/537.36', \n",
    "               \"Accept-Language\": \"en-US, en;q=0.9\"}\n",
    "\n",
    "\n",
    "# ----Helpers\n",
    "#------Fuction to parse dates--------\n",
    "def parse_listing_date(text):\n",
    "    text = text.lower()\n",
    "    today = datetime.today()\n",
    "\n",
    "    # Handle relative dates first\n",
    "    if 'added today' in text:\n",
    "        return today.date()\n",
    "    if 'added yesterday' in text:\n",
    "        return (today - timedelta(days=1)).date()\n",
    "\n",
    "    if 'updated today' in text:\n",
    "        return today.date()\n",
    "    if 'updated yesterday' in text:\n",
    "        return (today - timedelta(days=1)).date()\n",
    "\n",
    "    #Extract all absolute dates\n",
    "    dates = re.findall(r'(\\d{1,2} \\w{3} \\d{4})', text)\n",
    "\n",
    "    def to_date(d):\n",
    "        return datetime.strptime(d, '%d %b %Y').date()\n",
    "    # priority: added > updated > any\n",
    "    if 'added' in text:\n",
    "        for d in dates:\n",
    "            if text.index('added') < text.index(d):\n",
    "                return to_date(d)\n",
    "\n",
    "    if 'updated' in text:\n",
    "        for d in dates:\n",
    "            if text.index('updated') < text.index(d):\n",
    "                return to_date(d)\n",
    "\n",
    "    if dates:\n",
    "        return to_date(dates[0])\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "#---Function to extract digits in property benefits----\n",
    "def ex_property_features(listing):\n",
    "    ul = listing.find('ul', class_ = 'property-benefit')\n",
    "\n",
    "    if not ul:\n",
    "        return{\n",
    "            'bedrooms' : None,\n",
    "            'bathrooms' : None,\n",
    "            'toilets' : None\n",
    "        }\n",
    "\n",
    "    values = []\n",
    "    \n",
    "    for li in ul.find_all('li'):\n",
    "        text = li.get_text(strip = True)\n",
    "        match = re.search(r\"\\d+\", text)\n",
    "        values.append(int(match.group()) if match else None)\n",
    "\n",
    "    return {\n",
    "        'bedrooms': values[0] if len(values)>0 else None,\n",
    "        'bathrooms': values[1] if len(values)>1 else None,\n",
    "        'toilets': values[2] if len(values)>2 else None\n",
    "    }\n",
    "\n",
    "\n",
    "        \n",
    "data = []\n",
    "\n",
    "for i in range(start_page, end_page):\n",
    "    print(f\"Scraping page {i}...\")\n",
    "    # Attributing the sites url to a variable\n",
    "    url = f'https://privateproperty.ng/flats-apartments-for-rent?search=Ibadan+%2C+Oyo&auto=&bedroom=&min_price=&max_price=&button=&page={i}'\n",
    "    \n",
    "    # Sending a request to the website\n",
    "    response = requests.get(url, headers = Headers)\n",
    "    \n",
    "    # Parsing the web content to html\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # To by pass sponsored listings\n",
    "    page = soup.find('div', class_ = 'result-listings')\n",
    "    if not page:\n",
    "        continue\n",
    "\n",
    "    #To find all listings in each page\n",
    "    original_listings =[div for div in page.find_all('div', class_ = 'similar-listings-item')\n",
    "                        if 'sponsored-listing' not in div.get('class', [])]\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    for listing in original_listings:\n",
    "        #----TITLE----\n",
    "        Title_tag = listing.find('h3')\n",
    "        Title = Title_tag.text if Title_tag else None\n",
    "    \n",
    "        #----Listing URL--------\n",
    "        link_tag = listing.find('a',  href = True)\n",
    "        listing_url = Base_URL + link_tag['href'] if link_tag else None\n",
    "    \n",
    "        \n",
    "        # -------location------\n",
    "        location_tag = listing.find('p', class_ = 'listings-location').text.strip()\n",
    "        location = location_tag if location_tag else None\n",
    "    \n",
    "        # -----price--------\n",
    "        h4= listing.find('h4')\n",
    "        spans= h4.find_all('span')\n",
    "        price = spans[1].text.replace(',', '').split('/')[0] if spans else None\n",
    "\n",
    "        #---Listing date--------\n",
    "        date_tag = listing.find('h5')\n",
    "        posted_date = date_tag.get_text()\n",
    "        clean_date = parse_listing_date(posted_date)\n",
    "    \n",
    "        # -----Property Benefits-------\n",
    "       \n",
    "        features = (ex_property_features(listing))\n",
    "        beds = features['bedrooms']\n",
    "        baths = features['bathrooms']\n",
    "        toilets = features['toilets']\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        #---To append extraced values into 'data'----\n",
    "        data.append({\n",
    "            'Title': Title,\n",
    "            'Address': location,\n",
    "            'Price (₦)': price,\n",
    "            'Rent_period': 'Annually',\n",
    "            'Bedrooms': beds,\n",
    "            'Bathrooms': baths,\n",
    "            'Toilets': toilets, \n",
    "            'Listing_link': listing_url,\n",
    "            'Listed_Date' : clean_date\n",
    "        })\n",
    "\n",
    "     #----polite delay------\n",
    "    time.sleep(random.uniform(3,6))\n",
    "\n",
    "\n",
    "# ----Convert to DataFrame----\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['Bedrooms'] = df['Bedrooms'].astype('Int64')\n",
    "df['Bathrooms'] = df['Bathrooms'].astype('Int64')\n",
    "df['Toilets'] = df['Toilets'].astype('Int64')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-----To get the Specific area/location of the property:\n",
    "\n",
    "# importing a dataset of known Areas in Ibadan\n",
    "streets_df = pd.read_excel(r\"C:\\Users\\USER\\OneDrive\\Documents\\ibadan_areas_reference_only.xlsx\")\n",
    "street_list = streets_df[\"area_name\"].str.lower().tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--To match the Areas in the street dataset with linstings' address and extract the specific location from the address\n",
    "def extract_street(location, street_list):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "\n",
    "    location = location.lower()\n",
    "\n",
    "    for street in street_list:\n",
    "        # word-boundary match to avoid partial matches\n",
    "        pattern = r\"\\b\" + re.escape(street) + r\"\\b\"\n",
    "        if re.search(pattern, location):\n",
    "            return street.title()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Creating a new column for the extracted location area\n",
    "df[\"Location\"] = df[\"Address\"].apply(\n",
    "    lambda x: extract_street(x, street_list)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extracting the property type from the home Title\n",
    "\n",
    "# property types on the listings website\n",
    "property_types = [\n",
    "    \"block of flats\",\n",
    "    \"mini flat\",\n",
    "    \"self contain\",\n",
    "    \"shared apartment\"\n",
    "]\n",
    "\n",
    "\n",
    "# Matching the property type data to the home titlein the scraped data to extract the 'property type'\n",
    "\n",
    "def get_property_type(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    for p in property_types:\n",
    "        # use word boundary so we match whole terms, not substrings\n",
    "        if re.search(r\"\\b\" + re.escape(p) + r\"\\b\", text_lower):\n",
    "            return p.title()  # e.g., \"Block Of Flats\"\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply to description or title field\n",
    "df[\"property_type\"] = df[\"Title\"].apply(get_property_type)\n",
    "\n",
    "\n",
    "\n",
    "# -----To save as a csv file------\n",
    "df.to_csv('Ibadan_city_homes_for_rent.csv', index = False)\n",
    "\n",
    "print(f\"Done ✅ Scraped {len(df)} listings.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
